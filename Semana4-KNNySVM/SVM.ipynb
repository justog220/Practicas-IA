{"cells":[{"cell_type":"markdown","id":"c158c679-8401-4f73-87a5-39fc2e1c8902","metadata":{"id":"c158c679-8401-4f73-87a5-39fc2e1c8902"},"source":["## M치quinas de soporte vectorial (SVM)"]},{"cell_type":"markdown","id":"991eec7f-e5de-400b-936b-b60c11ec3c40","metadata":{"id":"991eec7f-e5de-400b-936b-b60c11ec3c40"},"source":["Es un algoritmo de aprendizaje supervisado donde el objetivo es maximizar el margen definido por la distancia entre el hiperplano de separaci칩n y los puntos (de los datos de entrenamiento) m치s cercanas al hiperplano. Estos puntos son denominados _vectores soporte_.\n","\n","La idea que hay detr치s de las SVM de _margen m치ximo_ consiste en seleccionar el hiperplano separador que est치 a la misma distancia de los puntos m치s cercanos de cada clase. \n","<pre>  \n","<center><img src=\"https://drive.google.com/uc?export=view&id=16Fk78bbxSnCTNLsLE3LPvAVQzSq3s-PT\"></center>\n","</pre>"]},{"cell_type":"markdown","id":"b819a697-1d55-49a6-a1d2-fafc5ae4faed","metadata":{"id":"b819a697-1d55-49a6-a1d2-fafc5ae4faed"},"source":["Las SVM tienen en su implementaci칩n una variable de holgura _C_ que permite que las restricciones no se cumplan de manera estricta. Esto es necesario en el caso de conjuntos que no son linealmente separables.\n","<pre>  \n","<center><img src=\"https://drive.google.com/uc?export=view&id=1bC72kprifClSNMjFp01KgXq4TxjSC_Vx\"></center>\n","</pre>\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"SEfGS7jDlCby"},"id":"SEfGS7jDlCby","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"fdfc2246-eeac-4e57-9d23-22a7fcb29ab2","metadata":{"id":"fdfc2246-eeac-4e57-9d23-22a7fcb29ab2"},"source":["## 游늬\n","A continuaci칩n vamos a usar las SVM con algunos datasets guardados en la carpeta data"]},{"cell_type":"code","execution_count":null,"id":"ba355931-dc34-407c-9f7d-186f49c4ccff","metadata":{"id":"ba355931-dc34-407c-9f7d-186f49c4ccff"},"outputs":[],"source":["# importamos las librer칤as necesarias\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","id":"fbccf152-5584-4980-b48c-7e9d304234d8","metadata":{"id":"fbccf152-5584-4980-b48c-7e9d304234d8"},"source":["### Dataset N췈 1"]},{"cell_type":"code","execution_count":null,"id":"064b67a7-124b-4b3e-ae1f-5581fdbff780","metadata":{"id":"064b67a7-124b-4b3e-ae1f-5581fdbff780"},"outputs":[],"source":["# Dataset data1.mat\n","archivo_mat = sio.loadmat('../data/data1.mat')\n","#archivo_matlab\n","X = archivo_mat['X']\n","y = archivo_mat['y'].flatten()\n","#y.shape"]},{"cell_type":"code","execution_count":null,"id":"1df5fe37-271d-4fd9-a5b9-96f77ab03db4","metadata":{"id":"1df5fe37-271d-4fd9-a5b9-96f77ab03db4"},"outputs":[],"source":["# Visualizamos los datos\n","markers = ('o', 's', '^', 'v')\n","colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n","plt.figure(figsize=(8,6))\n","for idx, cl in enumerate(np.unique(y)):\n","    plt.scatter(x=X[y == cl, 0], \n","                y=X[y == cl, 1],\n","                alpha=0.8, \n","                c=colors[idx],\n","                marker=markers[idx], \n","                label=cl, \n","                edgecolor='black')\n","plt.show()"]},{"cell_type":"markdown","id":"5114b664-4940-4855-925f-1634815c3737","metadata":{"id":"5114b664-4940-4855-925f-1634815c3737"},"source":["Este dataset es linealmente separable. Notar que se tiene un outlier en una de las clases. \n","\n","Parte de este ejercicio es probar con diferentes valores del par치metro C y ver qu칠 efecto tiene la presencia del outlier en la regi칩n de separaci칩n. "]},{"cell_type":"code","execution_count":null,"id":"bc1d6d34-3979-4412-bed0-29a0821e80cb","metadata":{"id":"bc1d6d34-3979-4412-bed0-29a0821e80cb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","def plot_decision_regions(X, y, clasificador, test_idx=None, resolution=0.02):\n","    \n","    # setup marker generator and color map\n","    markers = ('s', 'o', '^', 'v', 'x')\n","    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n","    cmap = ListedColormap(colors[:len(np.unique(y))])\n","\n","    # plot the decision surface\n","    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","\n","    \n","    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n","                           np.arange(x2_min, x2_max, resolution))\n","    \n","    Z = clasificador.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n","\n","    Z = Z.reshape(xx1.shape)\n","\n","    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n","    plt.xlim(xx1.min(), xx1.max())\n","    plt.ylim(xx2.min(), xx2.max())\n","\n","    for idx, cl in enumerate(np.unique(y)):\n","        plt.scatter(x=X[y == cl, 0], \n","                    y=X[y == cl, 1],\n","                    alpha=0.8, \n","                    c=colors[idx],\n","                    marker=markers[idx], \n","                    label=cl, \n","                    edgecolor='black')\n","\n","    # highlight test samples\n","    if test_idx:\n","        # plot all samples\n","        X_test, y_test = X[test_idx, :], y[test_idx]\n","\n","        plt.scatter(X_test[:, 0],\n","                    X_test[:, 1],\n","                    c=\"None\",\n","                    edgecolor='black',\n","                    alpha=1,\n","                    linewidth=1,\n","                    marker='o',\n","                    s=100, \n","                    label='test set')"]},{"cell_type":"code","execution_count":null,"id":"4dde9d0f-457d-4d85-87a4-00730002c929","metadata":{"id":"4dde9d0f-457d-4d85-87a4-00730002c929"},"outputs":[],"source":["# Normalizaci칩n de los datos\n","sc = StandardScaler()\n","sc.fit(X)                     \n","X_std = sc.transform(X) "]},{"cell_type":"markdown","source":["Utilice la clase [**SVC**](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) para entrenar una m치quina de soporte vectorial con kernel lineal y separar los datos.\n","\n","Pruebe con distintos valores del **par치metro 'C'**. Qu칠 puede observar al cambiar este valor? **Pruebe valores de C entre 1 y 150**"],"metadata":{"id":"9bF0gRoZ2BPX"},"id":"9bF0gRoZ2BPX"},{"cell_type":"code","execution_count":null,"id":"44fea754-0ee7-4223-a2f5-1cfec0ceb9f2","metadata":{"id":"44fea754-0ee7-4223-a2f5-1cfec0ceb9f2"},"outputs":[],"source":["from sklearn.svm import SVC\n","#------------------------------------------\n","\n","#---------------------------------------------\n","plt.figure(figsize=(8,6))\n","plot_decision_regions(X_std, y, clasificador=svm)"]},{"cell_type":"markdown","id":"36f779ce-bffb-4194-99ed-37320f4dd907","metadata":{"id":"36f779ce-bffb-4194-99ed-37320f4dd907"},"source":["### Dataset N췈 2\n","### SVM con kernel Gaussiano"]},{"cell_type":"code","execution_count":null,"id":"dce7f8a2-44a4-4f1b-9649-fedf2fe29970","metadata":{"id":"dce7f8a2-44a4-4f1b-9649-fedf2fe29970"},"outputs":[],"source":["# Dataset data2.mat\n","archivo_mat_2 = sio.loadmat('../data/data2.mat')\n","X_2 = archivo_mat_2['X']\n","y_2 = archivo_mat_2['y'].flatten()\n","X_2.shape"]},{"cell_type":"code","execution_count":null,"id":"120b7866-e453-400a-b9d4-15028bcc090c","metadata":{"id":"120b7866-e453-400a-b9d4-15028bcc090c"},"outputs":[],"source":["# Visualizamos los datos\n","markers = ('o', '+', 's', '^', 'v')\n","colors = ('lightgreen', 'blue', 'salmon','skyblue','red', 'gray', 'cyan')\n","plt.figure(figsize=(8,6))\n","for idx, cl in enumerate(np.unique(y_2)):\n","    plt.scatter(x=X_2[y_2 == cl, 0], \n","                y=X_2[y_2 == cl, 1],\n","                alpha=0.7, \n","                c=colors[idx],\n","                marker=markers[idx], \n","                label=cl, \n","                edgecolor='black')"]},{"cell_type":"markdown","id":"cc3a915b-6455-4c42-a37a-5f263a8dfbf5","metadata":{"id":"cc3a915b-6455-4c42-a37a-5f263a8dfbf5"},"source":["Como ver치 de la gr치fica, los datos no son linealmente separables. Con el kernel Gaussiano, el algoritmo del SVM podr치 encontrar la regi칩n de decisi칩n capaz de separar los datos correctamente y seguir los contornos del dataset."]},{"cell_type":"code","execution_count":null,"id":"391e4816-603b-4dd8-8c35-a251383135ff","metadata":{"id":"391e4816-603b-4dd8-8c35-a251383135ff"},"outputs":[],"source":["sc = StandardScaler()\n","sc.fit(X_2)                     \n","X_2_std = sc.transform(X_2) "]},{"cell_type":"markdown","id":"f0438b2d-931c-44d4-ad7b-c12cdff6c7c4","metadata":{"id":"f0438b2d-931c-44d4-ad7b-c12cdff6c7c4"},"source":["Uno de los _kernels_ m치s utilizado es el __radial basis function__ (RBF), que se conoce como __kernel Gaussiano__.\n","\n","Use la documentaci칩n para utilizar un modelo **kernel Gaussiano**. Modifique los **par치metros C y gamma**. Qu칠 observa al cambiar estos valores? **Pruebe valores de C entre 1 y 150 y entre 1 a 50 para gamma**."]},{"cell_type":"markdown","id":"49521b31-301f-4ba9-87be-feab6b9bbbd4","metadata":{"id":"49521b31-301f-4ba9-87be-feab6b9bbbd4"},"source":["El par치metro gamma de la funci칩n, es un par치metro que indica cu치nta influencia tiene una sola muestra, haciendo que el l칤mite de decisi칩n se ajuste mucho m치s a las muestras.\n","\n","La idea principal detr치s del uso de _kernels_ con datos que no son linealmente separables, es crear combinaciones no lineales de las caracter칤sticas originales y proyectarlas en un espacio de mayor dimensi칩n (mapeo mediante una funci칩n), donde los datos se vuelven linealmente separables "]},{"cell_type":"code","execution_count":null,"id":"a7733ab0-bd73-4358-9c87-6a0b702cebff","metadata":{"id":"a7733ab0-bd73-4358-9c87-6a0b702cebff"},"outputs":[],"source":["#------------------------------------------------------\n","\n","\n","#------------------------------------------------------\n","\n","plt.figure(figsize=(8,6))\n","plot_decision_regions(X_2_std, y_2, clasificador=svm_2,)\n","plt.xlim(-2,2)\n","plt.ylim(-2,2)"]},{"cell_type":"markdown","id":"11e12cda-e195-4865-a147-cf2c366c4752","metadata":{"id":"11e12cda-e195-4865-a147-cf2c366c4752"},"source":["### Dataset N췈 3\n","El siguiente dataset _data3.mat_ posee datos para entrenamiento (_X_, _y_) y datos para validaci칩n (_X_val_, _y_val_)"]},{"cell_type":"code","execution_count":null,"id":"8fb5500a-3535-41dd-9541-6aafa9c2a781","metadata":{"id":"8fb5500a-3535-41dd-9541-6aafa9c2a781"},"outputs":[],"source":["# Dataset data2.mat\n","archivo_mat_3 = sio.loadmat('../data/data3.mat')\n","X_3 = archivo_mat_3['X']\n","y_3 = archivo_mat_3['y'].flatten()\n","X_val_3 = archivo_mat_3['Xval']\n","y_val_3 = archivo_mat_3['yval'].flatten()\n","print(X_3.shape)\n","print(X_val_3.shape)"]},{"cell_type":"code","execution_count":null,"id":"50e1b354-f0ce-4e3e-af19-ca8a41454373","metadata":{"id":"50e1b354-f0ce-4e3e-af19-ca8a41454373"},"outputs":[],"source":["# Visualizamos los datos\n","markers = ('o', 's', '^', 'v')\n","colors = ('lightgreen', 'blue', 'salmon','skyblue','red', 'gray', 'cyan')\n","plt.figure(figsize=(8,6))\n","for idx, cl in enumerate(np.unique(y_3)):\n","    plt.scatter(x=X_3[y_3 == cl, 0], \n","                y=X_3[y_3 == cl, 1],\n","                alpha=0.7, \n","                c=colors[idx],\n","                marker=markers[idx], \n","                label=cl, \n","                edgecolor='black')"]},{"cell_type":"code","execution_count":null,"id":"e87792a2-e168-41ad-880c-d5e34aec8de5","metadata":{"id":"e87792a2-e168-41ad-880c-d5e34aec8de5"},"outputs":[],"source":["sc = StandardScaler()\n","sc.fit(X_3)                     \n","X_3_std = sc.transform(X_3)\n","X_val_3_std = sc.transform(X_val_3)\n","X_3_std.shape"]},{"cell_type":"markdown","source":["Se puede observar que los datos no son linealmente separables. Utilice un modelo con kernel gaussiano y pruebe con distintos valores de C y gamma. \n","\n","En esta ocasi칩n, implemente un algoritmo para entrenar modelos con cada uno de los siguientes valores de C y gamma en las listas, calcule el desempe침o de cada modelo y guarde esta informaci칩n en la forma [ (C, gamma), accuracy ]. Su algoritmo debe devolver la combinaci칩n (C, gamma) con el m치ximo valor de accuracy."],"metadata":{"id":"b_5Tioqm71W_"},"id":"b_5Tioqm71W_"},{"cell_type":"code","execution_count":null,"id":"36c8828c-b82f-40c1-82b8-b76a9e9bbeb4","metadata":{"id":"36c8828c-b82f-40c1-82b8-b76a9e9bbeb4"},"outputs":[],"source":["valores_C = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n","valores_gamma = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30] \n","\n","def obtener_mejor_desempe침o(valores_C, valores_gamma, X_train, y_train, X_val, y_val):\n","    #------------------------------------------------------\n","\n","\n","    #-----------------------------------------------------\n","    return C, gamma\n"]},{"cell_type":"code","execution_count":null,"id":"a7131529-b630-4b6d-a384-0462cffbbf04","metadata":{"id":"a7131529-b630-4b6d-a384-0462cffbbf04"},"outputs":[],"source":["#Entreno svm_3 con los par치metros de C y gamma obtenidos\n","#-----------------------------------------------------\n","\n","#---------------------------------------------------\n","\n","#calculo el score con los datos de validaci칩n\n","print(svm_3.score(X_val_3_std, y_val_3))"]},{"cell_type":"code","execution_count":null,"id":"6b1dcccc-4eb9-48ce-8cdc-db75b8e9bc84","metadata":{"id":"6b1dcccc-4eb9-48ce-8cdc-db75b8e9bc84"},"outputs":[],"source":["X_combined_std = np.vstack((X_3_std, X_val_3_std))\n","y_combined = np.hstack((y_3, y_val_3))\n","\n","plt.figure(figsize=(8,6))\n","plot_decision_regions(X_combined_std, y_combined, clasificador=svm_3)\n","plt.xlim(-2.5,2.5)\n","plt.ylim(-2,2)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}