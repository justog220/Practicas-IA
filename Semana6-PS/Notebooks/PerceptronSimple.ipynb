{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7512bc91",
   "metadata": {
    "id": "7512bc91"
   },
   "source": [
    "# Redes Neuronales Artificiales \n",
    "## Perceptrón Simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fa769-040c-4c53-83f0-a785db60e6c9",
   "metadata": {
    "id": "be5fa769-040c-4c53-83f0-a785db60e6c9",
    "tags": []
   },
   "source": [
    "Un Perceptrón simple (PS) es la red neuronal más sencilla que se puede considerar, está conformado por una sola neurona que posee N entradas y una función de transferencia de tipo umbral, tal como se ve en la siguiente figura:\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1c-Vh7kN8qvOPIVLYi_VxiFLZGuoZwRCp\" width=\"980\" alt=\"centered image\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189b931-5911-469d-a686-d7e194c8eddb",
   "metadata": {
    "id": "2189b931-5911-469d-a686-d7e194c8eddb",
    "tags": []
   },
   "source": [
    "Haciendo un pequeño cambio y llevando el umbral $\\theta$ hacia la izquierda en las ecuaciones anteriores, podemos definir un nuevo peso\n",
    "$w_0 = -\\theta$ y la entrada $x_0 = 1$ para poder escribir la salida de forma más compacta:\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1cThWTtQamhrPvbGwqSo0oqZOS86mXbGP\" width=\"780\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baeb641-fb5d-47d7-9a11-e984e0cf4a35",
   "metadata": {
    "id": "1baeb641-fb5d-47d7-9a11-e984e0cf4a35",
    "tags": []
   },
   "source": [
    "Podemos representar la salida con la siguiente expresión: $$y = sign(\\sum\\limits_{i=0}^N {x_i w_i})$$\n",
    "\n",
    "_**sign**_ corresponde a la función signo y es la _función de activación_ del perceptrón simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccbde2-e77f-4c62-9abf-b7dededc4724",
   "metadata": {
    "id": "99ccbde2-e77f-4c62-9abf-b7dededc4724"
   },
   "source": [
    "El PS permite resolver problemas linealmente separables mediante una recta o un hiperplano de separación con ordenada al origen distinta de cero gracias al término de _Bias_\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1ciZwhDhjUXMBCT6KFnnD7vPq4Pnt1-J0\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e50340-67d0-4c50-813b-45b9d1c1cbd0",
   "metadata": {
    "id": "69e50340-67d0-4c50-813b-45b9d1c1cbd0"
   },
   "source": [
    "Algoritmo de entrenamiento o _Regla del Perceptrón Simple_\n",
    "\n",
    "Esta regla puede implementarse siguiendo estos pasos:\n",
    "1. Inicializar el vector de pesos w con valores aleatorios entre 0 y 1.\n",
    "2. Presentar un patrón de entrada x y calcular la salida $$y = sign(x_0 w_0 + \\sum\\limits_{i=1}^N {x_i w_i})$$  Recordemos que $w_0$ es el término de bias y $x_0=1$, podemos representar la suma de productos usando un producto punto entre vectores: $$y = sign( w_0 + \\vec{w}^T \\cdot \\vec{x})$$\n",
    "\n",
    "3. Calcular el error entre la salida obtenida y la salida deseada $y_d$ $$e = y - y_d$$\n",
    "4. Ajustar los pesos de la red con la siguiente ecuación: $$ \\vec{w} = \\vec{w} + \\mu \\vec{e} \\cdot \\vec{x}$$ $\\mu$ es el coeficiente de aprendizaje o factor de entrenamiento (eta)\n",
    "5. Volver al paso 2 y repetir el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9236c0",
   "metadata": {
    "id": "df9236c0"
   },
   "outputs": [],
   "source": [
    "# Librerías a importar\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2436fd",
   "metadata": {
    "id": "8a2436fd"
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Perceptrón simple.\n",
    "    \n",
    "    Parámetros\n",
    "    ------------\n",
    "    eta : float\n",
    "        factor de entrenamiento (entre 0.0 y 1.0)\n",
    "    n_iter : int\n",
    "        iteraciones para el entrenamiento.\n",
    "    random_state : int\n",
    "        Semilla generadora de números aleatorios para la inicialización de los pesos.\n",
    "    \n",
    "    Atributos\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Pesos despues del entrenamiento.\n",
    "    mal_clasificados_ : list\n",
    "        Número de desaciertos en cada época\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Función de entrenamiento.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape = [n_muestras, n_caracteristicas]\n",
    "          vector de entrenamiento\n",
    "        y : array, shape = [n_muestras]\n",
    "          vector target.\n",
    "          \n",
    "        Returns\n",
    "        -------\n",
    "        self : objeto\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        rgen = RandomState(self.random_state)\n",
    "        #inicializo los pesos con valores aleatorios entre 0 y 1\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        #self.w_ = np.ones((1 + X.shape[1],1)).flatten()\n",
    "        self.mal_clasificados_ = []\n",
    "        self.errores_ = []\n",
    "        # para cada época\n",
    "        for _ in range(self.n_iter):\n",
    "            \n",
    "            mal_clasificados = 0\n",
    "            \n",
    "            # para cada valor de (x, target) en el vector de entrada:x y vector de salida(target):y\n",
    "            for xi, target in zip(X, y):\n",
    "                \n",
    "                # cálculo de la salida \n",
    "                y_salida = self.predict(xi)\n",
    "                # --------cálculo del error y actualización del vector de pesos-------\n",
    "                error = target - y_salida                \n",
    "                update = self.eta * (error)\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                self.errores_.append(error)\n",
    "                #------------------------------------------------------------------------\n",
    "                #si update es distinto de 0 la salida predicha difiere de la salida esperada\n",
    "                mal_clasificados += int(error != 0.0)\n",
    "                \n",
    "            self.mal_clasificados_.append(mal_clasificados)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def calcular_entrada(self, X):\n",
    "        \"\"\"cálculo de la entrada al perceptrón\"\"\"\n",
    "        # -------suma de los productos de los valores de entrada y los pesos -----------        \n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "        #-------------------------------------------------------------------------------\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"devuelve la etiqueta de la clase pertenciente después de aplicar la fn. de activación\"\"\"\n",
    "        # la función de activación es la función signo: \n",
    "        # 0 si el resultado de calcular_entrada < 0\n",
    "        # 1 si el resultado de calcular_entrada >= 0\n",
    "        return np.where( self.calcular_entrada(X) >= 0.0, 1, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02a46c-4251-4780-a422-8b5ba173f71d",
   "metadata": {
    "id": "0f02a46c-4251-4780-a422-8b5ba173f71d"
   },
   "source": [
    "## Dataset Iris \n",
    "El conjunto de datos flor Iris contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris versicolor e Iris virginica), en total 150 muestras. Se midió cuatro rasgos de cada muestra: el largo y ancho del sépalo y pétalo, en centímetros. \n",
    "\n",
    ">Nosotros vamos a utilizar nuestro perceptrón para separar dos clases de flores (Iris setosa e Iris versicolor) según dos de sus características: Largo de sépalo (primer columna en el dataset) y largo de pétalo (tercer columna).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28151f66",
   "metadata": {
    "id": "28151f66"
   },
   "outputs": [],
   "source": [
    "#Iris Dataset: tamaño total 150 datos\n",
    "#Este dataset está organizado en 50 datos de Iris-setosa, 50 datos de Iris-versicolor y 50 datos de Iris-virginica\n",
    "\n",
    "#Cargo el Dataset --> Devuelve un dataframe\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "#muestra las últimas 5 líneas del dataset\n",
    "df.tail()\n",
    "#print(type(df))\n",
    "# Observar que el dataset tiene 5 columnas, donde la última corresponde a las etiquetas de las clases esperadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c6744-b0f1-421c-884e-0f98b108dfdc",
   "metadata": {
    "id": "031c6744-b0f1-421c-884e-0f98b108dfdc"
   },
   "source": [
    "# Graficamos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037aef30",
   "metadata": {
    "id": "037aef30"
   },
   "outputs": [],
   "source": [
    "# Target: extraigo 100 etiquetas de clase correspondientes a 50 flores Iris-setosa y 50 Iris-versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "#print(y)\n",
    "\n",
    "#convertimos las etiquetas de clases en  0 (Iris-setosa)  y 1 (Iris-versicolor)\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "#print(y)\n",
    "\n",
    "#Extraigo la primera y tercera columna del dataset como características de entrada\n",
    "# columna 0 : longitud de sépalo, columna 2 : longitud de pétalo\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "#print(X)\n",
    "\n",
    "#plot de los datos\n",
    "plt.scatter( X[:50, 0], X[:50, 1], color='red', marker='o', label='setosa')\n",
    "plt.scatter( X[50:100, 0], X[50:100, 1], color='blue', marker='x', label='versicolor')\n",
    "plt.xlabel('x1 = largo de sépalo [cm]')\n",
    "plt.ylabel('x2 = largo de pétalo [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Hasta aquí tenemos la distribución de una muestra de flores del dataset Iris teniendo en cuenta dos características\n",
    "#longitudes del sépalo y pétalo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8b099-f254-40df-9843-68a859c4e2b2",
   "metadata": {
    "id": "f0a8b099-f254-40df-9843-68a859c4e2b2"
   },
   "source": [
    "# Entrenamiento del Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795c4f9",
   "metadata": {
    "id": "c795c4f9"
   },
   "outputs": [],
   "source": [
    "#Instancio un objeto de la clase Perceptron\n",
    "perceptron = Perceptron(eta=0.01, n_iter=10, random_state=100)\n",
    "\n",
    "#llamo a su método fit\n",
    "perceptron.fit(X,y)\n",
    "print(perceptron.w_)\n",
    "\n",
    "#Grafico el número de errores por época\n",
    "plt.plot( range(1, len(perceptron.mal_clasificados_)+1),  perceptron.mal_clasificados_,  marker = 'o' )\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Mal clasificados por iteración')\n",
    "plt.show()\n",
    "\n",
    "#Grafico el número de errores por época\n",
    "plt.plot( range(1, len(perceptron.errores_)+1),  perceptron.errores_)\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('Errores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02969f89-9b89-44d0-b15c-c1e258662bf6",
   "metadata": {
    "id": "02969f89-9b89-44d0-b15c-c1e258662bf6"
   },
   "source": [
    "Recordemos la ecuación: $$y = sign(w_0 + \\sum\\limits_{i=1}^N {x_i w_i})$$ \n",
    "\n",
    "Para este problema con dos características (x1 = longitudes del sépalo y x2= longitudes de pétalo ), la ecuación resulta: \n",
    "\n",
    "$$y = sign(x_1 w_1 + x_2 w_2 + w_0)$$ \n",
    "\n",
    "Donde se separan las dos clases de flores, tendremos la frontera de decisión, dada por la ecuación:\n",
    "\n",
    "$$x_1 w_1 + x_2 w_2 + w_0 = 0$$ \n",
    "\n",
    "De esta ecuación podemos despejar la recta $x_2$ en función de $x_1$ que separa las clases en el espacio de soluciones\n",
    "\n",
    "$$x_2 + x_1 \\frac{w_1}{w_2} + \\frac{w_0}{w_2} = 0$$ \n",
    "\n",
    "$$x_2 =  -\\frac{w_1}{w_2}x_1 - \\frac{w_0}{w_2} $$ \n",
    "\n",
    "La pendiente de la recta  $ m = -\\frac{w_1}{w_2}$ y la ordenada al origen $ b = - \\frac{w_0}{w_2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e7402-6c3e-48d6-aac0-36b01009a147",
   "metadata": {
    "id": "2f1e7402-6c3e-48d6-aac0-36b01009a147"
   },
   "source": [
    "### _Ahora vamos a graficar esta recta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a34485-59c2-4a9a-8aed-66fc872c9928",
   "metadata": {
    "id": "a5a34485-59c2-4a9a-8aed-66fc872c9928"
   },
   "outputs": [],
   "source": [
    "#------------------ Representación de la recta ------------------------------------\n",
    "# vector de pesos del perceptrón entrenado\n",
    "w = perceptron.w_\n",
    "# cálculo de la pendiente\n",
    "m = - w[1]/w[2]\n",
    "# cálculo de la ordenada al origen\n",
    "b = - w[0]/w[2]\n",
    "# x1 corresponde a la longitud de sépalos\n",
    "x1 = X[:, 0]\n",
    "x2 = m*x1 + b\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "#plot de la recta\n",
    "plt.plot(x1, x2, color='green')\n",
    "#plot de los datos\n",
    "plt.scatter( X[:50, 0], X[:50, 1], color='red', marker='.', label='setosa')\n",
    "plt.scatter( X[50:100, 0], X[50:100, 1], color='blue', marker='*', label='versicolor')\n",
    "plt.xlabel('x1 = largo de sépalo [cm]')\n",
    "plt.ylabel('x2 = largo de pétalo [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.xlim([4, 7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1BehvGntO5dX",
   "metadata": {
    "id": "1BehvGntO5dX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, clasificador, test_idx=None, resolution=0.02):\n",
    "    \n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'o', '^', 'v', 'x')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    \n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    \n",
    "    Z = clasificador.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c=\"None\",\n",
    "                    edgecolor='black',\n",
    "                    alpha=1,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28456588-1c71-47ce-b23f-f58c96207140",
   "metadata": {
    "id": "28456588-1c71-47ce-b23f-f58c96207140"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plot_decision_regions(X,y, perceptron)\n",
    "plt.xlabel('longitud de pétalo')\n",
    "plt.ylabel('ancho de pétalo ')\n",
    "plt.xlim([4, 7.2])\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
